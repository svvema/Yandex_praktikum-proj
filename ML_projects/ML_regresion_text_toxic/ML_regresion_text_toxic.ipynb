{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Токсичные комметарии\n",
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "### Инструкция по выполнению проекта\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак.\n",
    "_______________________________________\n",
    "\n",
    "##### [1. Подготовка данных](#Part_1)\n",
    "\n",
    "##### [2. Обучение моделей](#Part_2)\n",
    "* [2.1 Логистическая регрессия](#Part_2.1)\n",
    "* [2.2 Случайный лес ](#Part_2.2)\n",
    "* [2.3 Градиентый бустинг](#Part_2.3)\n",
    "\n",
    "##### [3. Выводы](#Part_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part_1'></a>\n",
    "# 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from tqdm import tqdm, notebook\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0\n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7  Your vandalism to the Matt Shirvington article...      0\n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10167887648758234"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].mean() #процент токсичных комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем очистку и лемматизацию текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    cl_text = re.sub(r\"[^a-zA-Z' ]\", ' ', text)\n",
    "    cl_text = cl_text.split()\n",
    "    return ' '.join(cl_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    text = clear_text(text)\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return ' '.join([lemmatizer.lemmatize(text) for text in word_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237d8e32686443f19defe1feb6924caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=159571.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "notebook.tqdm.pandas()\n",
    "\n",
    "df['lemma'] = df['text'].progress_apply(lambda x: clear_text(lemmatize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 159571)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part_2'></a>\n",
    "# 2. Обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, shuffle=True, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((127656, 3), (31915, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизируем лемматизированный текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (127656, 143930)\n"
     ]
    }
   ],
   "source": [
    "corpus = train['lemma']\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_features_train = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "features_train = count_features_train.fit_transform(corpus) \n",
    "\n",
    "print(\"Размер матрицы:\", features_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = count_features_train.transform(test['lemma'])\n",
    "\n",
    "target_train = train['toxic']\n",
    "target_test = test['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part_2.1'></a>\n",
    "## 2.1 Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logic = LogisticRegression().fit(features_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выберем порог определения класса по трейну и выставим его для предсказания теста\n",
    "def prob(model, lr, hr, step, feature, target):\n",
    "    probabilities_one_valid = model.predict_proba(feature)[:, 1]\n",
    "\n",
    "    for threshold in np.arange(lr, hr, step):\n",
    "        predicted_valid = probabilities_one_valid > threshold \n",
    "        f1 = f1_score(target, pd.Series(predicted_valid))\n",
    "    \n",
    "        print(\"Порог = {:.2f} | f1 = {:.3f}\".format(threshold, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.20 | f1 = 0.831\n",
      "Порог = 0.21 | f1 = 0.833\n",
      "Порог = 0.22 | f1 = 0.835\n",
      "Порог = 0.23 | f1 = 0.836\n",
      "Порог = 0.24 | f1 = 0.835\n",
      "Порог = 0.25 | f1 = 0.837\n",
      "Порог = 0.26 | f1 = 0.836\n",
      "Порог = 0.27 | f1 = 0.834\n",
      "Порог = 0.28 | f1 = 0.832\n",
      "Порог = 0.29 | f1 = 0.829\n"
     ]
    }
   ],
   "source": [
    "prob(logic, 0.2, 0.3, 0.01, features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = pd.Series((logic.predict_proba(features_test)[:,1]>0.25).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7828833096478762"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(target_test, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part_2.2'></a>\n",
    "## 2.2 Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state=42, n_estimators = 100).fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.25 | f1 = 0.777\n",
      "Порог = 0.26 | f1 = 0.780\n",
      "Порог = 0.27 | f1 = 0.782\n",
      "Порог = 0.28 | f1 = 0.785\n",
      "Порог = 0.29 | f1 = 0.784\n",
      "Порог = 0.30 | f1 = 0.781\n",
      "Порог = 0.31 | f1 = 0.782\n",
      "Порог = 0.32 | f1 = 0.779\n",
      "Порог = 0.33 | f1 = 0.777\n",
      "Порог = 0.34 | f1 = 0.774\n"
     ]
    }
   ],
   "source": [
    "prob(forest, 0.25, 0.35, 0.01, features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7845181674565561"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = pd.Series((forest.predict_proba(features_test)[:,1]>0.28).astype(int))\n",
    "f1_score(target_test, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part_2.3'></a>\n",
    "## 2.3 Градиентный бустинг"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gbm = lgb.LGBMClassifier(random_state=42)\n",
    "param_set = {'learning_rate':np.arange(0.30, 0.38, 0.02)\n",
    "             }\n",
    "\n",
    "\n",
    "gsearch = GridSearchCV(gbm, param_grid=param_set, n_jobs=-1, cv=3, verbose=10)\n",
    "\n",
    "lgb_model = gsearch.fit(features_train, target_train)\n",
    "lgb_model.best_params_, lgb_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "[20]\ttraining's binary_logloss: 0.11995\n",
      "[40]\ttraining's binary_logloss: 0.100453\n",
      "[60]\ttraining's binary_logloss: 0.0883308\n",
      "[80]\ttraining's binary_logloss: 0.0794595\n",
      "[100]\ttraining's binary_logloss: 0.0722971\n",
      "[120]\ttraining's binary_logloss: 0.0663133\n",
      "[140]\ttraining's binary_logloss: 0.0612156\n",
      "[160]\ttraining's binary_logloss: 0.0568776\n",
      "[180]\ttraining's binary_logloss: 0.0529086\n",
      "[200]\ttraining's binary_logloss: 0.0494532\n",
      "[220]\ttraining's binary_logloss: 0.0462622\n",
      "[240]\ttraining's binary_logloss: 0.0434855\n",
      "[260]\ttraining's binary_logloss: 0.0409287\n",
      "[280]\ttraining's binary_logloss: 0.0385425\n",
      "[300]\ttraining's binary_logloss: 0.0364071\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\ttraining's binary_logloss: 0.0364071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.38, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=300, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "gbm = lgb.LGBMClassifier(learning_rate=0.38,\n",
    "                         n_estimators=300,\n",
    "                        random_state=42\n",
    "                       )\n",
    "# fit\n",
    "gbm.fit(features_train, target_train,\n",
    "        eval_set=[(features_train, target_train)],\n",
    "        eval_metric='logloss',\n",
    "        early_stopping_rounds=5,\n",
    "        verbose = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.35 | f1 = 0.777\n",
      "Порог = 0.36 | f1 = 0.777\n",
      "Порог = 0.37 | f1 = 0.777\n",
      "Порог = 0.38 | f1 = 0.778\n",
      "Порог = 0.39 | f1 = 0.778\n",
      "Порог = 0.40 | f1 = 0.777\n",
      "Порог = 0.41 | f1 = 0.777\n",
      "Порог = 0.42 | f1 = 0.776\n",
      "Порог = 0.43 | f1 = 0.776\n",
      "Порог = 0.44 | f1 = 0.776\n",
      "Порог = 0.45 | f1 = 0.775\n"
     ]
    }
   ],
   "source": [
    "prob(gbm, 0.35, 0.45, 0.01, features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7777958123681221"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = pd.Series((gbm.predict_proba(features_test)[:,1]>0.38).astype(int))\n",
    "f1_score(target_test, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part_3'></a>\n",
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для построения модели классификация твиттов по токсичности, мы проделали следующие шаги:\n",
    "* текст очищен от посторонних символов, оставлен только английский алфавит\n",
    "* текст твиттов лемматизирован\n",
    "* текст переведен в векторную форму с помощью TfidfVectorizer\n",
    "* обучены три модели классификации\n",
    "* на всех трех моделях удалось достичь метрику f1 больше 0.75\n",
    "* Самой быстрой моделью стала логистическая регрессия, а самой точной случайный лес"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
